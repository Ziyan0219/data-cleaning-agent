# ğŸ„ Cattle Data Cleaning Agent

An AI-powered data quality control system specifically designed for cattle weight data and ready-to-load status validation. This system uses intelligent classification to automatically handle data quality issues while maintaining human oversight for critical decisions.

## ğŸ¯ Key Features

### **Intelligent Data Classification**
- **ğŸ”´ Extreme Outliers**: Automatically removes impossible weight data (>1.3x normal threshold)
- **ğŸŸ¡ Suspicious Data**: Flags questionable weights for manual review (1.0-1.3x threshold)  
- **ğŸŸ¢ Label Corrections**: Automatically fixes obvious labeling errors

### **Business Logic**
- **Weight Thresholds**: 500-1500 lbs normal range, >1950 lbs extreme outliers
- **Smart Processing**: Balances automation with human oversight
- **Quality Scoring**: Comprehensive data quality improvement metrics

### **Production Ready**
- **Web Interface**: User-friendly FastAPI web application
- **Detailed Reports**: Comprehensive processing reports with actionable insights
- **Error Handling**: Robust error handling and logging
- **Scalable Architecture**: Modular design for easy extension

## ğŸš€ Quick Start

### **Method 1: Web Interface (Recommended)**

```bash
# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.template .env
# Edit .env and add your OpenAI API key

# Start web server
python app_v2.py

# Open browser to http://localhost:8000
```

### **Method 2: Command Line**

```bash
# Test with sample data
python test_system.py

# Process custom data
python main.py --requirements "Process cattle data for weight validation" --data-source "path/to/your/data.csv"
```

## ğŸ“ Project Structure

```
data_cleaning_agent_english/
â”œâ”€â”€ ğŸ“Š data/                          # Data directory
â”‚   â”œâ”€â”€ input/                        # Input data files
â”‚   â”‚   â”œâ”€â”€ cattle_data.csv          # Sample cattle data with quality issues
â”‚   â”‚   â””â”€â”€ sample_data.csv          # General sample data
â”‚   â”œâ”€â”€ output/                       # Cleaned data output
â”‚   â””â”€â”€ temp/                         # Temporary processing files
â”œâ”€â”€ ğŸ¤– src/                           # Source code
â”‚   â”œâ”€â”€ agents/                       # AI agents
â”‚   â”‚   â”œâ”€â”€ main_controller_fixed.py  # Working main controller
â”‚   â”‚   â”œâ”€â”€ data_analysis_agent.py    # Data analysis agent
â”‚   â”‚   â”œâ”€â”€ data_cleaning_agent.py    # Data cleaning agent
â”‚   â”‚   â”œâ”€â”€ quality_validation_agent.py # Quality validation agent
â”‚   â”‚   â””â”€â”€ result_aggregation_agent.py # Result aggregation agent
â”‚   â”œâ”€â”€ config/                       # Configuration management
â”‚   â”‚   â””â”€â”€ settings.py              # Application settings
â”‚   â”œâ”€â”€ schemas/                      # Data schemas
â”‚   â”‚   â””â”€â”€ state.py                 # State definitions
â”‚   â””â”€â”€ utils/                        # Utility functions
â”‚       â””â”€â”€ json_utils.py            # JSON serialization utilities
â”œâ”€â”€ ğŸŒ Web Interface
â”‚   â”œâ”€â”€ app_v2.py                    # Working FastAPI web application
â”‚   â””â”€â”€ app.py                       # Original web application
â”œâ”€â”€ ğŸ§ª Testing
â”‚   â”œâ”€â”€ test_system.py               # System test script
â”‚   â””â”€â”€ main.py                      # Command line interface
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ README.md                    # This file
â”‚   â””â”€â”€ data_cleaning_agent_english_guide.md # Detailed development guide
â””â”€â”€ âš™ï¸ Configuration
    â”œâ”€â”€ requirements.txt             # Python dependencies
    â”œâ”€â”€ .env.template               # Environment variables template
    â””â”€â”€ .gitignore                  # Git ignore rules
```

## ğŸ„ Sample Data Format

The system expects CSV files with the following columns:

```csv
lot_id,entry_weight_lbs,exit_weight_lbs,days_on_feed,breed,feed_type,ready_to_load
LOT001,650,1250,180,Angus,Corn,Yes
LOT002,680,1320,185,Hereford,Mixed,Yes
LOT003,720,1180,175,Charolais,Corn,No
```

### **Data Quality Issues Handled**
1. **Extreme outliers**: LOT005 (2100 lbs entry) â†’ Automatically deleted
2. **Suspicious weights**: LOT022 (1850 lbs) â†’ Flagged for manual review  
3. **Label errors**: Normal weight but marked "No" â†’ Auto-corrected to "Yes"

## ğŸ“Š Processing Logic

### **Three-Tier Classification System**

```
ğŸ”´ EXTREME OUTLIERS (>1950 lbs)
â”œâ”€â”€ Action: Automatic deletion
â”œâ”€â”€ Rationale: Impossible weights for cattle
â””â”€â”€ Report: Lists all deleted lots with weights

ğŸŸ¡ SUSPICIOUS WEIGHTS (1500-1950 lbs)  
â”œâ”€â”€ Action: Flag for manual review
â”œâ”€â”€ Rationale: Possible but requires verification
â””â”€â”€ Report: Lists lots needing human inspection

ğŸŸ¢ LABEL ERRORS (Normal weight + "No" status)
â”œâ”€â”€ Action: Automatic correction to "Yes"
â”œâ”€â”€ Rationale: Clear data entry errors
â””â”€â”€ Report: Lists all corrected labels
```

## ğŸ“‹ Sample Report Output

```
ğŸ„ CATTLE DATA CLEANING REPORT
==================================================
ğŸ“… Generated: 2025-07-13 12:27:17

ğŸ“Š EXECUTIVE SUMMARY
--------------------
â€¢ Original lots: 30
â€¢ Processed lots: 26  
â€¢ Removed lots: 4
â€¢ Quality improvement: 100.0%

ğŸ” PROBLEM CLASSIFICATION
-------------------------
1. EXTREME OUTLIERS (Deleted): 4 lots
   â€¢ LOT005: Entry=2100lbs, Exit=2800lbs
   â€¢ LOT012: Entry=3200lbs, Exit=4100lbs

2. SUSPICIOUS WEIGHTS (Manual Review): 0 lots
   â€¢ No suspicious weights found

3. LABEL ERRORS (Auto-corrected): 8 lots
   â€¢ LOT003: Changed from 'no' to 'Yes'
   â€¢ LOT007: Changed from 'no' to 'Yes'

âš™ï¸ PROCESSING ACTIONS
--------------------
âœ‚ï¸ DELETED 4 lots: Weight exceeds 1.3x normal threshold
ğŸ”§ CORRECTED 8 labels: Normal weight but incorrectly marked as not ready

ğŸ¯ NEXT STEPS
------------
â€¢ No manual review required
â€¢ All remaining lots are ready for processing

ğŸ“ˆ DATA QUALITY METRICS
-----------------------
â€¢ Ready to load: 26/26 lots (100.0%)
â€¢ Data completeness: 100.0%
â€¢ Weight range compliance: 26/26 lots
```

## ğŸ› ï¸ Installation & Setup

### **Prerequisites**
- Python 3.8+
- OpenAI API key

### **Installation Steps**

1. **Clone the repository**
   ```bash
   git clone https://github.com/Ziyan0219/data-cleaning-agent.git
   cd data-cleaning-agent
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure environment**
   ```bash
   cp .env.template .env
   # Edit .env file and add your OpenAI API key:
   # OPENAI_API_KEY=sk-your-actual-api-key-here
   ```

4. **Test the system**
   ```bash
   python test_system.py
   ```

5. **Start web interface**
   ```bash
   python app_v2.py
   # Open http://localhost:8000 in your browser
   ```

## ğŸ”§ Configuration

### **Environment Variables (.env)**
```bash
# Required: OpenAI API Configuration
OPENAI_API_KEY=sk-your-actual-api-key-here

# Optional: Additional API Keys
ANTHROPIC_API_KEY=your-anthropic-key-if-needed
```

### **Weight Thresholds (Customizable)**
```python
# In src/agents/main_controller_fixed.py
weight_thresholds = {
    "min_normal": 500,    # Minimum normal weight (lbs)
    "max_normal": 1500,   # Maximum normal weight (lbs)  
    "extreme_threshold": 1950  # Extreme outlier threshold (lbs)
}
```

## ğŸ§ª Testing

### **System Test**
```bash
python test_system.py
```

### **Web Interface Test**
```bash
python app_v2.py
# Navigate to http://localhost:8000/test
```

### **Custom Data Test**
```bash
python main.py --requirements "Your cleaning requirements" --data-source "path/to/your/data.csv"
```

## ğŸ“ˆ Performance Metrics

- **Processing Speed**: ~0.02 seconds for 30 lots
- **Quality Improvement**: Up to 100% issue resolution
- **Accuracy**: Intelligent classification with minimal false positives
- **Scalability**: Handles datasets from 10s to 1000s of records

## ğŸ” Troubleshooting

### **Common Issues**

1. **Import Errors**
   ```bash
   # Solution: Use the working version
   python app_v2.py  # Instead of app.py
   python test_system.py  # For testing
   ```

2. **API Key Issues**
   ```bash
   # Check your .env file
   cat .env
   # Ensure OPENAI_API_KEY is set correctly
   ```

3. **Data Format Issues**
   ```bash
   # Ensure CSV has required columns:
   # lot_id, entry_weight_lbs, exit_weight_lbs, ready_to_load
   ```

### **Debug Mode**
```bash
# Enable detailed logging
export LOG_LEVEL=DEBUG
python test_system.py
```

## ğŸš€ Deployment

### **Local Development**
```bash
python app_v2.py
# Access at http://localhost:8000
```

### **Production Deployment**
```bash
# Using uvicorn
uvicorn app_v2:app --host 0.0.0.0 --port 8000

# Using gunicorn
gunicorn app_v2:app -w 4 -k uvicorn.workers.UvicornWorker
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“ Contact

If you have questions or suggestions, please contact us through:

- Submit Issue: [GitHub Issues](https://github.com/Ziyan0219/data-cleaning-agent/issues)
- Email: ziyanxinbci@gmail.com

## ğŸ† Acknowledgments

- Built with LangChain and FastAPI
- Designed for agricultural data quality control
- Optimized for cattle weight validation workflows

---

**Version 2.1.0** - Simplified & Reliable | Production Ready ğŸ‰

